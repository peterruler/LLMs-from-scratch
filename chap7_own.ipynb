{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peterruler/LLMs-from-scratch/blob/main/chap7_own.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "eb1c4f0b-d648-4474-b194-d1dcf2c5981f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb1c4f0b-d648-4474-b194-d1dcf2c5981f",
        "outputId": "efd66ac8-8a78-458c-b715-3150c1add566"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of entries: 1100\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import urllib\n",
        "\n",
        "def download_and_load_file(file_path, url):\n",
        "    if not os.path.exists(file_path):\n",
        "        with urllib.request.urlopen(url) as response:\n",
        "            text_data = response.read().decode(\"utf-8\")\n",
        "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "            file.write(text_data)\n",
        "\n",
        "    with open(file_path, \"r\") as file:\n",
        "        data = json.load(file)\n",
        "    return data\n",
        "\n",
        "file_path = \"instruction-data.json\"\n",
        "url = (\n",
        "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
        "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
        ")\n",
        "\n",
        "\n",
        "data = download_and_load_file(file_path, url)\n",
        "print(\"Number of entries:\", len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "3dd4dcbe-656a-4845-99b7-87322f707cfb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dd4dcbe-656a-4845-99b7-87322f707cfb",
        "outputId": "ec5d8db6-e561-4ec5-bf5f-215f1e965dff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example entry:\n",
            " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
          ]
        }
      ],
      "source": [
        "print(\"Example entry:\\n\", data[50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "c39cb12a-6f15-420a-9a33-c0a51c4c47e4",
      "metadata": {
        "id": "c39cb12a-6f15-420a-9a33-c0a51c4c47e4"
      },
      "outputs": [],
      "source": [
        "def format_input(entry):\n",
        "    instruction_text = (\n",
        "        f\"Below is an instruction that describes a task. \"\n",
        "        f\"Write a response that appropriately completes the request.\"\n",
        "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
        "    )\n",
        "\n",
        "    input_text = (\n",
        "        f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
        "    )\n",
        "    return instruction_text + input_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "81090edc-ed2f-456e-aec0-57350a376943",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81090edc-ed2f-456e-aec0-57350a376943",
        "outputId": "6bdf788c-34ea-4954-e14b-7db2920acb77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Identify the correct spelling of the following word.\n",
            "\n",
            "### Input:\n",
            "Ocassion\n",
            "\n",
            "### Response:\n",
            "The correct spelling is 'Occasion.'\n"
          ]
        }
      ],
      "source": [
        "model_input = format_input(data[50])\n",
        "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
        "print(model_input + desired_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "e39108f8-196e-4f3b-a649-64885ebb4f27",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e39108f8-196e-4f3b-a649-64885ebb4f27",
        "outputId": "825d73fe-2586-49c9-cfbf-69f865afac6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "What is an antonym of 'complicated'?\n",
            "\n",
            "### Response:\n",
            "An antonym of 'complicated' is 'simple'.\n"
          ]
        }
      ],
      "source": [
        "model_input = format_input(data[999])\n",
        "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
        "print(model_input + desired_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "f334625e-359b-4b99-a6f4-b626a026854c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f334625e-359b-4b99-a6f4-b626a026854c",
        "outputId": "de8b2e2e-a04f-4027-b440-a54ce90ee7d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set length: 935\n",
            "Validation set length: 55\n",
            "Test set length: 110\n"
          ]
        }
      ],
      "source": [
        "train_portion = int(len(data) * 0.85)\n",
        "test_portion = int(len(data) * 0.1)\n",
        "val_portion = len(data) - train_portion - test_portion\n",
        "\n",
        "train_data = data[:train_portion]\n",
        "test_data = data[train_portion:train_portion + test_portion]\n",
        "val_data = data[train_portion + test_portion:]\n",
        "\n",
        "print(\"Training set length:\", len(train_data))\n",
        "print(\"Validation set length:\", len(val_data))\n",
        "print(\"Test set length:\", len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "aad68dd8-fdf3-4ee3-a9c7-a7d721fb107e",
      "metadata": {
        "id": "aad68dd8-fdf3-4ee3-a9c7-a7d721fb107e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class InstructionDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "        self.encoded_texts = []\n",
        "        for entry in data:\n",
        "            instruction_plus_input = format_input(entry)\n",
        "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
        "            full_text = instruction_plus_input + response_text\n",
        "            self.encoded_texts.append(\n",
        "                tokenizer.encode(full_text)\n",
        "            )\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.encoded_texts[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "48d07271-2048-4b1f-9de9-222d8055baa7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48d07271-2048-4b1f-9de9-222d8055baa7",
        "outputId": "9208aea8-4486-4422-da96-ebf9c207a31b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50256]\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "388aebb0-3934-42ef-82a6-e06bd0ab8002",
      "metadata": {
        "id": "388aebb0-3934-42ef-82a6-e06bd0ab8002"
      },
      "outputs": [],
      "source": [
        "def custom_collate_draft_1(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "    inputs_lst = []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        new_item += [pad_token_id]\n",
        "\n",
        "\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        inputs = torch.tensor(padded[:-1])\n",
        "        inputs_lst.append(inputs)\n",
        "\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    return inputs_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "33f57043-a992-4ec7-a53c-59371fd31b62",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33f57043-a992-4ec7-a53c-59371fd31b62",
        "outputId": "0a70d99e-b0a8-425c-dcf2-8ce9333eec05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n"
          ]
        }
      ],
      "source": [
        "inputs_1 = [0, 1, 2, 3, 4]\n",
        "inputs_2 = [5, 6]\n",
        "inputs_3 = [7, 8, 9]\n",
        "batch = (\n",
        "    inputs_1,\n",
        "    inputs_2,\n",
        "    inputs_3\n",
        ")\n",
        "print(custom_collate_draft_1(batch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "78d8d7bf-4099-45f6-933a-56a634918e07",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78d8d7bf-4099-45f6-933a-56a634918e07",
        "outputId": "b288d464-a987-438a-afe7-a2104cc8baa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n",
            "tensor([[    1,     2,     3,     4, 50256],\n",
            "        [    6, 50256, 50256, 50256, 50256],\n",
            "        [    8,     9, 50256, 50256, 50256]])\n"
          ]
        }
      ],
      "source": [
        "def custom_collate_draft_2(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "    inputs_lst, targets_lst = [], []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        new_item += [pad_token_id]\n",
        "\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        inputs = torch.tensor(padded[:-1])\n",
        "        targets = torch.tensor(padded[1:])\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "    return inputs_tensor, targets_tensor\n",
        "\n",
        "inputs, targets = custom_collate_draft_2(batch)\n",
        "print(inputs)\n",
        "print(targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "f028473e-29b3-4c10-83fb-eae208e070fa",
      "metadata": {
        "id": "f028473e-29b3-4c10-83fb-eae208e070fa"
      },
      "outputs": [],
      "source": [
        "def custom_collate_fn(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    ignore_index=-100,\n",
        "    allowed_max_length=None,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "    inputs_lst, targets_lst = [], []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        new_item += [pad_token_id]\n",
        "\n",
        "\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        inputs = torch.tensor(padded[:-1])\n",
        "        targets = torch.tensor(padded[1:])\n",
        "\n",
        "        mask = targets == pad_token_id\n",
        "        indices = torch.nonzero(mask).squeeze()\n",
        "        if indices.numel() > 1:\n",
        "            targets[indices[1:]] = ignore_index\n",
        "\n",
        "        if allowed_max_length is not None:\n",
        "            inputs = inputs[:allowed_max_length]\n",
        "            targets = targets[:allowed_max_length]\n",
        "\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "    return inputs_tensor, targets_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "a300dbff-39d9-4910-90d5-9b1c7027c0d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a300dbff-39d9-4910-90d5-9b1c7027c0d2",
        "outputId": "d42e897a-6dd0-41c4-d66e-b5316009034f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n",
            "tensor([[    1,     2,     3,     4, 50256],\n",
            "        [    6, 50256,  -100,  -100,  -100],\n",
            "        [    8,     9, 50256,  -100,  -100]])\n"
          ]
        }
      ],
      "source": [
        "inputs, targets = custom_collate_fn(batch)\n",
        "print(inputs)\n",
        "print(targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "8b827027-340c-4db1-9576-e4ac6ab1c12b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b827027-340c-4db1-9576-e4ac6ab1c12b",
        "outputId": "e9d7f8be-0851-4641-87d9-f6f4a645c8a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.1269)\n"
          ]
        }
      ],
      "source": [
        "logits_1 = torch.tensor(\n",
        "    [[-1.0, 1.0],\n",
        "     [-0.5, 1.5]]\n",
        ")\n",
        "targets_1 = torch.tensor([0, 1]) # Correct token indices to generate\n",
        "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
        "print(loss_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "27281cb3-762d-4786-a197-84897a0ac39e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27281cb3-762d-4786-a197-84897a0ac39e",
        "outputId": "c69a1eb3-5100-457c-d9ce-43a8b9d92b70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7936)\n"
          ]
        }
      ],
      "source": [
        "logits_2 = torch.tensor(\n",
        "    [[-1.0, 1.0],\n",
        "     [-0.5, 1.5],\n",
        "     [-0.5, 1.5]]\n",
        ")\n",
        "targets_2 = torch.tensor([0, 1, 1])\n",
        "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
        "print(loss_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "d65493ff-bce3-4139-8464-ef0eea04b0fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d65493ff-bce3-4139-8464-ef0eea04b0fd",
        "outputId": "b305c0a7-b2e5-4da3-9a4b-3b7c1b58a871"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.1269)\n",
            "loss_1 == loss_3: tensor(True)\n"
          ]
        }
      ],
      "source": [
        "targets_3 = torch.tensor([0, 1, -100])\n",
        "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
        "print(loss_3)\n",
        "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "8870791b-e56f-4992-927f-3a84d50d5a5b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8870791b-e56f-4992-927f-3a84d50d5a5b",
        "outputId": "69bf3c72-f271-4ee1-c6d4-e2f23c3db691"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "print(\"Device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "23652322-f4fb-4dcc-b0d8-f399813c90db",
      "metadata": {
        "id": "23652322-f4fb-4dcc-b0d8-f399813c90db"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "\n",
        "customized_collate_fn = partial(\n",
        "    custom_collate_fn,\n",
        "    device=device,\n",
        "    allowed_max_length=1024\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "56988593-f525-43c1-98ff-e0d0afc04438",
      "metadata": {
        "id": "56988593-f525-43c1-98ff-e0d0afc04438"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_dataset = InstructionDataset(train_data, tokenizer)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "val_dataset = InstructionDataset(val_data, tokenizer)\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "test_dataset = InstructionDataset(test_data, tokenizer)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "c69f5341-3e2e-4cc5-b964-baa5d096aa3d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c69f5341-3e2e-4cc5-b964-baa5d096aa3d",
        "outputId": "02bc36b6-9685-4ea8-83f9-ad7ac9b17042"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader:\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 79]) torch.Size([8, 79])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 58]) torch.Size([8, 58])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 57]) torch.Size([8, 57])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n"
          ]
        }
      ],
      "source": [
        "print(\"Train loader:\")\n",
        "for inputs, targets in train_loader:\n",
        "    print(inputs.shape, targets.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "653dbfc8-d991-4e59-b5d0-29de82dfa750",
      "metadata": {
        "id": "653dbfc8-d991-4e59-b5d0-29de82dfa750"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "976384d3-e248-403e-bbe3-2c8de714d837",
      "metadata": {
        "id": "976384d3-e248-403e-bbe3-2c8de714d837"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out,\n",
        "                 context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (d_out % num_heads == 0), \\\n",
        "            \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.triu(torch.ones(context_length, context_length),\n",
        "                       diagonal=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "        keys = self.W_key(x)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(\n",
        "            b, num_tokens, self.num_heads, self.head_dim\n",
        "        )\n",
        "\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        attn_scores = queries @ keys.transpose(2, 3)\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(\n",
        "            attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        context_vec = context_vec.contiguous().view(\n",
        "            b, num_tokens, self.d_out\n",
        "        )\n",
        "        context_vec = self.out_proj(context_vec)\n",
        "        return context_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "b0753d85-cd05-4066-955e-023d50fe69b5",
      "metadata": {
        "id": "b0753d85-cd05-4066-955e-023d50fe69b5"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "f229dfde-814c-4fd1-9152-e553f60436ff",
      "metadata": {
        "id": "f229dfde-814c-4fd1-9152-e553f60436ff"
      },
      "outputs": [],
      "source": [
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "0749d16b-f6f4-492f-ae04-f25efebd0212",
      "metadata": {
        "id": "0749d16b-f6f4-492f-ae04-f25efebd0212"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "94868064-17b1-4414-9821-53100a44e70e",
      "metadata": {
        "id": "94868064-17b1-4414-9821-53100a44e70e"
      },
      "outputs": [],
      "source": [
        "# from chapter03 import MultiHeadAttention\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "893a3eed-58ad-4d66-bca8-cd5d670f68c6",
      "metadata": {
        "id": "893a3eed-58ad-4d66-bca8-cd5d670f68c6"
      },
      "outputs": [],
      "source": [
        "def assign(left, right):\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, \"\n",
        "                          \"Right: {right.shape}\"\n",
        "        )\n",
        "    return torch.nn.Parameter(torch.tensor(right))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "155c9800-4497-4e64-9c6a-2982969a53b8",
      "metadata": {
        "id": "155c9800-4497-4e64-9c6a-2982969a53b8"
      },
      "outputs": [],
      "source": [
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "\n",
        "        pos_embeds = self.pos_emb(\n",
        "            torch.arange(seq_len, device=in_idx.device)\n",
        "        )\n",
        "        x = tok_embeds + pos_embeds\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "95a814a4-cfa8-4824-a8a2-04d7421db700",
      "metadata": {
        "id": "95a814a4-cfa8-4824-a8a2-04d7421db700"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
        "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
        "\n",
        "    for b in range(len(params[\"blocks\"])):\n",
        "        q_w, k_w, v_w = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "        q_b, k_b, v_b = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.weight,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.bias,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].norm1.scale = assign(\n",
        "            gpt.trf_blocks[b].norm1.scale,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm1.shift = assign(\n",
        "            gpt.trf_blocks[b].norm1.shift,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "        gpt.trf_blocks[b].norm2.scale = assign(\n",
        "            gpt.trf_blocks[b].norm2.scale,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm2.shift = assign(\n",
        "            gpt.trf_blocks[b].norm2.shift,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright (c) Sebastian Raschka under Apache License 2.0 (see LICENSE.txt).\n",
        "# Source for \"Build a Large Language Model From Scratch\"\n",
        "#   - https://www.manning.com/books/build-a-large-language-model-from-scratch\n",
        "# Code: https://github.com/rasbt/LLMs-from-scratch\n",
        "\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import requests\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def download_and_load_gpt2(model_size, models_dir):\n",
        "    # Validate model size\n",
        "    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n",
        "    if model_size not in allowed_sizes:\n",
        "        raise ValueError(f\"Model size not in {allowed_sizes}\")\n",
        "\n",
        "    # Define paths\n",
        "    model_dir = os.path.join(models_dir, model_size)\n",
        "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
        "    backup_base_url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/gpt2\"\n",
        "    filenames = [\n",
        "        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n",
        "        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n",
        "        \"model.ckpt.meta\", \"vocab.bpe\"\n",
        "    ]\n",
        "\n",
        "    # Download files\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "    for filename in filenames:\n",
        "        file_url = os.path.join(base_url, model_size, filename)\n",
        "        backup_url = os.path.join(backup_base_url, model_size, filename)\n",
        "        file_path = os.path.join(model_dir, filename)\n",
        "        download_file(file_url, file_path, backup_url)\n",
        "\n",
        "    # Load settings and params\n",
        "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
        "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\"), \"r\", encoding=\"utf-8\"))\n",
        "    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
        "\n",
        "    return settings, params\n",
        "\n",
        "\n",
        "def download_file(url, destination, backup_url=None):\n",
        "    def _attempt_download(download_url):\n",
        "        response = requests.get(download_url, stream=True, timeout=60)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        file_size = int(response.headers.get(\"Content-Length\", 0))\n",
        "\n",
        "        # Check if file exists and has same size\n",
        "        if os.path.exists(destination):\n",
        "            file_size_local = os.path.getsize(destination)\n",
        "            if file_size and file_size == file_size_local:\n",
        "                print(f\"File already exists and is up-to-date: {destination}\")\n",
        "                return True\n",
        "\n",
        "        block_size = 1024  # 1 KB\n",
        "        desc = os.path.basename(download_url)\n",
        "        with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=desc) as progress_bar:\n",
        "            with open(destination, \"wb\") as file:\n",
        "                for chunk in response.iter_content(chunk_size=block_size):\n",
        "                    if chunk:\n",
        "                        file.write(chunk)\n",
        "                        progress_bar.update(len(chunk))\n",
        "        return True\n",
        "\n",
        "    try:\n",
        "        if _attempt_download(url):\n",
        "            return\n",
        "    except requests.exceptions.RequestException:\n",
        "        if backup_url is not None:\n",
        "            print(f\"Primary URL ({url}) failed. Attempting backup URL: {backup_url}\")\n",
        "            try:\n",
        "                if _attempt_download(backup_url):\n",
        "                    return\n",
        "            except requests.exceptions.RequestException:\n",
        "                pass\n",
        "\n",
        "        error_message = (\n",
        "            f\"Failed to download from both primary URL ({url})\"\n",
        "            f\"{' and backup URL (' + backup_url + ')' if backup_url else ''}.\"\n",
        "            \"\\nCheck your internet connection or the file availability.\\n\"\n",
        "            \"For help, visit: https://github.com/rasbt/LLMs-from-scratch/discussions/273\"\n",
        "        )\n",
        "        print(error_message)\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "\n",
        "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
        "    # Initialize parameters dictionary with empty blocks for each layer\n",
        "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
        "\n",
        "    # Iterate over each variable in the checkpoint\n",
        "    for name, _ in tf.train.list_variables(ckpt_path):\n",
        "        # Load the variable and remove singleton dimensions\n",
        "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
        "\n",
        "        # Process the variable name to extract relevant parts\n",
        "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
        "\n",
        "        # Identify the target dictionary for the variable\n",
        "        target_dict = params\n",
        "        if variable_name_parts[0].startswith(\"h\"):\n",
        "            layer_number = int(variable_name_parts[0][1:])\n",
        "            target_dict = params[\"blocks\"][layer_number]\n",
        "\n",
        "        # Recursively access or create nested dictionaries\n",
        "        for key in variable_name_parts[1:-1]:\n",
        "            target_dict = target_dict.setdefault(key, {})\n",
        "\n",
        "        # Assign the variable array to the last key\n",
        "        last_key = variable_name_parts[-1]\n",
        "        target_dict[last_key] = variable_array\n",
        "\n",
        "    return params\n"
      ],
      "metadata": {
        "id": "3Ev3I7owbdd8"
      },
      "id": "3Ev3I7owbdd8",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "0d4a925e-75a6-461a-8ceb-6293414d0614",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d4a925e-75a6-461a-8ceb-6293414d0614",
        "outputId": "e425c7c8-1957-41c1-dc33-99ee46cc8dce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 174kiB/s]\n",
            "encoder.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 634kiB/s]\n",
            "hparams.json: 100%|██████████| 91.0/91.0 [00:00<00:00, 206kiB/s]\n",
            "model.ckpt.data-00000-of-00001: 100%|██████████| 1.42G/1.42G [08:46<00:00, 2.69MiB/s]\n",
            "model.ckpt.index: 100%|██████████| 10.4k/10.4k [00:00<00:00, 22.8MiB/s]\n",
            "model.ckpt.meta: 100%|██████████| 927k/927k [00:01<00:00, 560kiB/s]\n",
            "vocab.bpe: 100%|██████████| 456k/456k [00:01<00:00, 367kiB/s]\n"
          ]
        }
      ],
      "source": [
        "# from gpt_download import download_and_load_gpt2\n",
        "# from chapter04 import GPTModel\n",
        "# from chapter05 import load_weights_into_gpt\n",
        "\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 1024,  # Context length\n",
        "    \"drop_rate\": 0.0,        # Dropout rate\n",
        "    \"qkv_bias\": True         # Query-key-value bias\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "\n",
        "settings, params = download_and_load_gpt2(\n",
        "    model_size=model_size,\n",
        "    models_dir=\"gpt2\"\n",
        ")\n",
        "\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "b2d14ae1-ba0c-4777-be17-7f506b907f12",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2d14ae1-ba0c-4777-be17-7f506b907f12",
        "outputId": "972217e3-9994-43c6-eddf-c7f3105f45ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "input_text = format_input(val_data[0])\n",
        "print(input_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "e4a6008f-e431-400a-9162-ac9a733cc06c",
      "metadata": {
        "id": "e4a6008f-e431-400a-9162-ac9a733cc06c"
      },
      "outputs": [],
      "source": [
        "def generate(model, idx, max_new_tokens, context_size,\n",
        "             temperature=0.0, top_k=None, eos_id=None):\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "        if top_k is not None:\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(\n",
        "                logits < min_val,\n",
        "                torch.tensor(float('-inf')).to(logits.device),\n",
        "                logits\n",
        "            )\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "            probs = torch.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
        "        if idx_next == eos_id:\n",
        "            break\n",
        "        idx = torch.cat((idx, idx_next), dim=1)\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "2bf0112a-87d6-4eee-9bce-59f4ca6b0f1f",
      "metadata": {
        "id": "2bf0112a-87d6-4eee-9bce-59f4ca6b0f1f"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "# from chapter04 import generate_text_simple\n",
        "\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0)\n",
        "    return tokenizer.decode(flat.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "28e90cbf-c436-4d44-9bc6-b44cf0afc9f1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28e90cbf-c436-4d44-9bc6-b44cf0afc9f1",
        "outputId": "6ca1c670-2fba-4c69-e751-39c04e3de751"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "input_text = format_input(val_data[0])\n",
        "print(input_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "2729ba16-ef38-49c4-8a4f-39c311527f0b",
      "metadata": {
        "id": "2729ba16-ef38-49c4-8a4f-39c311527f0b"
      },
      "outputs": [],
      "source": [
        "# from chapter05 import generate, text_to_token_ids, token_ids_to_text\n",
        "\n",
        "token_ids = generate(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(input_text, tokenizer),\n",
        "    max_new_tokens=35,\n",
        "    context_size=BASE_CONFIG[\"context_length\"],\n",
        "    eos_id=50256,\n",
        ")\n",
        "generated_text = token_ids_to_text(token_ids, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "6541687b-f879-46fa-8ce3-0c592eca4393",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6541687b-f879-46fa-8ce3-0c592eca4393",
        "outputId": "cac7f094-939d-4057-ca18-f0be268740a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Response:\n",
            "\n",
            "The chef cooks the meal every day.\n",
            "\n",
            "### Instruction:\n",
            "\n",
            "Convert the active sentence to passive: 'The chef cooks the\n"
          ]
        }
      ],
      "source": [
        "response_text = generated_text[len(input_text):].strip()\n",
        "print(response_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "6b7a2184-f477-4bb9-9960-f27a91ef023c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "6b7a2184-f477-4bb9-9960-f27a91ef023c",
        "outputId": "ea46005d-2bef-4795-e1d3-08e634151610"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom chapter05 import (\\n    calc_loss_loader,\\n    train_model_simple\\n)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "'''\n",
        "from chapter05 import (\n",
        "    calc_loss_loader,\n",
        "    train_model_simple\n",
        ")\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "ea6ab8b7-66ce-49fe-846f-680e75dd7c91",
      "metadata": {
        "id": "ea6ab8b7-66ce-49fe-846f-680e75dd7c91"
      },
      "outputs": [],
      "source": [
        "def train_model_simple(model, train_loader, val_loader,\n",
        "                       optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            loss = calc_loss_batch(\n",
        "                input_batch, target_batch, model, device\n",
        "            )\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            tokens_seen += input_batch.numel()\n",
        "            global_step += 1\n",
        "\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, \"\n",
        "                      f\"Val loss {val_loss:.3f}\"\n",
        "                )\n",
        "\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "    return train_losses, val_losses, track_tokens_seen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "bd1dc715-4c5b-4e87-9c4f-176f6fb50bed",
      "metadata": {
        "id": "bd1dc715-4c5b-4e87-9c4f-176f6fb50bed"
      },
      "outputs": [],
      "source": [
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(\n",
        "                input_batch, target_batch, model, device\n",
        "            )\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "a7e2e0a1-e4da-4c05-a2db-37c447f0c23a",
      "metadata": {
        "id": "a7e2e0a1-e4da-4c05-a2db-37c447f0c23a"
      },
      "outputs": [],
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch = input_batch.to(device)\n",
        "    target_batch = target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(\n",
        "        logits.flatten(0, 1), target_batch.flatten()\n",
        "    )\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "55cd02f9-f9f3-4e94-9cef-87d32c4becd4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55cd02f9-f9f3-4e94-9cef-87d32c4becd4",
        "outputId": "4f07b5b3-ca69-4a50-deb0-493df5055c59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 3.825908899307251\n",
            "Validation loss: 3.761933422088623\n"
          ]
        }
      ],
      "source": [
        "model.to(device)\n",
        "torch.manual_seed(123)\n",
        "\n",
        "with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(\n",
        "        train_loader, model, device, num_batches=5\n",
        "    )\n",
        "    val_loss = calc_loss_loader(\n",
        "        val_loader, model, device, num_batches=5\n",
        ")\n",
        "\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "0c1273b6-93be-4b63-8371-03018c0f291e",
      "metadata": {
        "id": "0c1273b6-93be-4b63-8371-03018c0f291e"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(\n",
        "            train_loader, model, device, num_batches=eval_iter\n",
        "        )\n",
        "        val_loss = calc_loss_loader(\n",
        "            val_loader, model, device, num_batches=eval_iter\n",
        "        )\n",
        "    model.train()\n",
        "    return train_loss, val_loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model, idx=encoded,\n",
        "            max_new_tokens=50, context_size=context_size\n",
        "        )\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))\n",
        "    model.train()"
      ],
      "metadata": {
        "id": "2xcO4OMueBZe"
      },
      "id": "2xcO4OMueBZe",
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_simple(model, idx,\n",
        "                         max_new_tokens, context_size):\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "\n",
        "        logits = logits[:, -1, :]\n",
        "        probas = torch.softmax(logits, dim=-1)\n",
        "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
        "        idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "    return idx"
      ],
      "metadata": {
        "id": "dSguckMIeWaC"
      },
      "id": "dSguckMIeWaC",
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "411c06d9-0aab-42b6-9698-52ce9e0e3fb2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "411c06d9-0aab-42b6-9698-52ce9e0e3fb2",
        "outputId": "f2755ea3-65e0-49f7-b292-d8e51dad0b39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 0.327, Val loss 0.654\n",
            "Ep 1 (Step 000005): Train loss 0.408, Val loss 0.679\n",
            "Ep 1 (Step 000010): Train loss 0.343, Val loss 0.675\n",
            "Ep 1 (Step 000015): Train loss 0.391, Val loss 0.691\n",
            "Ep 1 (Step 000020): Train loss 0.328, Val loss 0.721\n",
            "Ep 1 (Step 000025): Train loss 0.353, Val loss 0.719\n",
            "Ep 1 (Step 000030): Train loss 0.358, Val loss 0.750\n",
            "Ep 1 (Step 000035): Train loss 0.353, Val loss 0.777\n",
            "Ep 1 (Step 000040): Train loss 0.311, Val loss 0.749\n",
            "Ep 1 (Step 000045): Train loss 0.326, Val loss 0.738\n",
            "Ep 1 (Step 000050): Train loss 0.315, Val loss 0.729\n",
            "Ep 1 (Step 000055): Train loss 0.404, Val loss 0.727\n",
            "Ep 1 (Step 000060): Train loss 0.341, Val loss 0.736\n",
            "Ep 1 (Step 000065): Train loss 0.311, Val loss 0.716\n",
            "Ep 1 (Step 000070): Train loss 0.293, Val loss 0.690\n",
            "Ep 1 (Step 000075): Train loss 0.290, Val loss 0.693\n",
            "Ep 1 (Step 000080): Train loss 0.293, Val loss 0.727\n",
            "Ep 1 (Step 000085): Train loss 0.254, Val loss 0.792\n",
            "Ep 1 (Step 000090): Train loss 0.310, Val loss 0.771\n",
            "Ep 1 (Step 000095): Train loss 0.262, Val loss 0.748\n",
            "Ep 1 (Step 000100): Train loss 0.283, Val loss 0.732\n",
            "Ep 1 (Step 000105): Train loss 0.272, Val loss 0.725\n",
            "Ep 1 (Step 000110): Train loss 0.279, Val loss 0.709\n",
            "Ep 1 (Step 000115): Train loss 0.275, Val loss 0.675\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
            "Ep 2 (Step 000120): Train loss 0.247, Val loss 0.669\n",
            "Ep 2 (Step 000125): Train loss 0.244, Val loss 0.676\n",
            "Ep 2 (Step 000130): Train loss 0.255, Val loss 0.697\n",
            "Ep 2 (Step 000135): Train loss 0.257, Val loss 0.732\n",
            "Ep 2 (Step 000140): Train loss 0.225, Val loss 0.749\n",
            "Ep 2 (Step 000145): Train loss 0.220, Val loss 0.731\n",
            "Ep 2 (Step 000150): Train loss 0.232, Val loss 0.713\n",
            "Ep 2 (Step 000155): Train loss 0.243, Val loss 0.734\n",
            "Ep 2 (Step 000160): Train loss 0.238, Val loss 0.740\n",
            "Ep 2 (Step 000165): Train loss 0.228, Val loss 0.731\n",
            "Ep 2 (Step 000170): Train loss 0.196, Val loss 0.732\n",
            "Ep 2 (Step 000175): Train loss 0.215, Val loss 0.724\n",
            "Ep 2 (Step 000180): Train loss 0.225, Val loss 0.721\n",
            "Ep 2 (Step 000185): Train loss 0.255, Val loss 0.713\n",
            "Ep 2 (Step 000190): Train loss 0.216, Val loss 0.701\n",
            "Ep 2 (Step 000195): Train loss 0.196, Val loss 0.688\n",
            "Ep 2 (Step 000200): Train loss 0.207, Val loss 0.684\n",
            "Ep 2 (Step 000205): Train loss 0.219, Val loss 0.685\n",
            "Ep 2 (Step 000210): Train loss 0.213, Val loss 0.689\n",
            "Ep 2 (Step 000215): Train loss 0.250, Val loss 0.705\n",
            "Ep 2 (Step 000220): Train loss 0.199, Val loss 0.719\n",
            "Ep 2 (Step 000225): Train loss 0.193, Val loss 0.730\n",
            "Ep 2 (Step 000230): Train loss 0.195, Val loss 0.716\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef prepares the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The\n",
            "Training completed in 0.83 minutes.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "torch.manual_seed(123)\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(), lr=0.00005, weight_decay=0.1\n",
        ")\n",
        "num_epochs = 2\n",
        "\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "f7f78f4c-a603-44a9-9045-44f424fdab97",
      "metadata": {
        "id": "f7f78f4c-a603-44a9-9045-44f424fdab97"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(\n",
        "        epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
        "    )\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "    ax2 = ax1.twiny()\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "    fig.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "4f3c03d6-3d5b-4e35-860b-e5f56548135c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "4f3c03d6-3d5b-4e35-860b-e5f56548135c",
        "outputId": "71d8a5cb-fdbf-4c7c-ad03-811e2ae1af1b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# from chapter05 import plot_losses\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "06217007-4440-45eb-a67a-eacddf8295b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06217007-4440-45eb-a67a-eacddf8295b5",
        "outputId": "0e89278e-6d49-42fc-b622-dd242c473519"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Rewrite the sentence using a simile.\n",
            "\n",
            "### Input:\n",
            "The car is very fast.\n",
            "\n",
            "Correct response:\n",
            ">> The car is as fast as lightning.\n",
            "\n",
            "Model response:\n",
            ">> The car is as fast as a cheetah.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "What type of cloud is typically associated with thunderstorms?\n",
            "\n",
            "Correct response:\n",
            ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
            "\n",
            "Model response:\n",
            ">> Thunderstorms are typically associated with a type of cloud called a cumulus.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Name the author of 'Pride and Prejudice'.\n",
            "\n",
            "Correct response:\n",
            ">> Jane Austen.\n",
            "\n",
            "Model response:\n",
            ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
            "-------------------------------------\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "for entry in test_data[:3]:\n",
        "    input_text = format_input(entry)\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "\n",
        "    response_text = (\n",
        "        generated_text[len(input_text):]\n",
        "        .replace(\"### Response:\", \"\")\n",
        "        .strip()\n",
        "    )\n",
        "    print(input_text)\n",
        "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
        "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
        "    print(\"-------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "1b3e9627-34e5-4582-8797-fd572afa8069",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b3e9627-34e5-4582-8797-fd572afa8069",
        "outputId": "7ab9e8c9-044b-4a9a-8b86-dd0fe77399c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 110/110 [01:05<00:00,  1.68it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "\n",
        "    response_text = (\n",
        "        generated_text[len(input_text):]\n",
        "        .replace(\"### Response:\", \"\")\n",
        "        .strip()\n",
        "    )\n",
        "    test_data[i][\"model_response\"] = response_text\n",
        "\n",
        "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
        "    json.dump(test_data, file, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "6b68cb4f-cdb8-45fd-bf77-500e5b098387",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b68cb4f-cdb8-45fd-bf77-500e5b098387",
        "outputId": "8b3e5ec3-2921-475f-e3a6-c7725c983435"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a cheetah.'}\n"
          ]
        }
      ],
      "source": [
        "print(test_data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "58d0c46d-52db-4ca9-811e-898f02b8d53f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58d0c46d-52db-4ca9-811e-898f02b8d53f",
        "outputId": "c089215b-ec88-4d55-85cc-ee20cb5708bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as gpt2-medium355M-sft.pth\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
        "torch.save(model.state_dict(), file_name)\n",
        "print(f\"Model saved as {file_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "77d41a00-428c-4389-8706-43a3cd2b9bd7",
      "metadata": {
        "id": "77d41a00-428c-4389-8706-43a3cd2b9bd7"
      },
      "outputs": [],
      "source": [
        "# model.load_state_dict(torch.load(\"gpt2-medium355M-sft.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "bee0a8bd-f10a-4baa-90d5-7a669c242150",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "bee0a8bd-f10a-4baa-90d5-7a669c242150",
        "outputId": "f704092f-6c37-424c-cbe3-ed11cd94284d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_51212568-d9b6-4ae9-b637-db2d7d431201\", \"gpt2-medium355M-sft.pth\", 1725962793)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(file_name)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}